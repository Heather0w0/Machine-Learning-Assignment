{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "73traix79fevng5a62autj",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "<h1>Homework - Part 2: Training and evaluating predictive models</h1>\n",
                "<h2>Machine Learning for Business Analytics (CIS432)</h2>\n",
                "<h3>Simon Business School</h3>\n",
                "\n",
                "__Instructor__: Yaron Shaposhnik\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "l4z9lt1onbp0tl75ycrij5r",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "### Instructions\n",
                "\n",
                "In this homework assignment, we will train and evaluate predictive models based on the HELOC dataset. We will reinforce the following concepts and techniques: \n",
                "* Preprocessing, imputers, and pipelines\n",
                "* Model training, Hyper-parameter tuning, grid search, and prediction\n",
                "* The validation set and cross validation methods\n",
                "* Confusion matrix\n",
                "* Performance metrics"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "2o6sqq0mdn8drqb5hddcy",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "## Answer key\n",
                "\n",
                "This assignment (as well as others) is graded by comparing your answers (that is, the variables and Python objects you create) with precomputed answers. This allows you to get immediate feedback in order to find your errors and correct them. The downside of this approach is that the grading code is strict and even slight deviations from the desired outputs could result in reduction of points. \n",
                "\n",
                "To make this learning experience more efficient, the objects that you are asked to generate are provided to you in the variable `ANSWER_KEY`. Questions may ask you to assign a value (like a number or object such as data frame) to a variable. For example, in the second question you are asked to assign the variable `n_rows` with a certain value. To view the correct answer simply run the command `ANSWER_KEY['n_rows']`. \n",
                "\n",
                "Note that the answer key is provided to you __for debugging purposes only__. Using it in your final submission or hard-coding solutions __will be considered plagiarism__ and be reported to the student disciplinary committee."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "metadata": {
                "cellIdentifier": "ay1sk41ovfedgga65dh6ev",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "imports",
                    "locked": true,
                    "points": 0,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "# you may ignore this cell\n",
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pickle\n",
                "from IPython.display import Image\n",
                "\n",
                "if os.name == 'nt':\n",
                "    ANSWER_KEY_FILE_NAME = \"answer_key(win)-part2.p\"\n",
                "elif os.name == 'posix':\n",
                "    ANSWER_KEY_FILE_NAME = \"answer_key(unix)-part2.p\"\n",
                "else:\n",
                "    raise Exception('The code was not tested on',os.name)\n",
                "\n",
                "GENERATE_ANSWER_KEY=False\n",
                "\n",
                "if GENERATE_ANSWER_KEY: \n",
                "    ANSWER_KEY = {} \n",
                "else:        \n",
                "    with open(ANSWER_KEY_FILE_NAME, \"rb\") as f:\n",
                "        ANSWER_KEY = pickle.load( f )       "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {
                "cellIdentifier": "1f3rzrt14fit7j5cmxyxdm",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "# An example for using answer key\n",
                "if GENERATE_ANSWER_KEY==False: \n",
                "    print(ANSWER_KEY['conf_matrix'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "uophbi1u4a5rponppfkgs",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "# Beginning"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "e9t1y2btoj81gsyaoychwz",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "# Part 1: Formulating a prediction problem\n",
                "\n",
                "In the the previous assignment we explored the HELOC dataset. \n",
                "\n",
                "Load the csv file `heloc_dataset_v1(exc empty rows.).csv_pre(-1,asis).csv` into the variable `df`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {
                "cellIdentifier": "p77p46xcxf8nfhh5yu934",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "df = pd.read_csv(\"heloc_dataset_v1(exc empty rows.).csv_pre(-1,asis).csv\")\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {
                "cellIdentifier": "v1xv27x3yu9m7izm0eyp",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q1a_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['df']\n",
                "diff = sol.compare(df, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing df'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {
                "cellIdentifier": "0k6pf6r9wwqbo1cepnedds",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['df'].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "xed6ee1fhn2ba7znbh2ib",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "It has 9871 rows and 24 columns. Each row represents a loan taken by a customer, and columns provide information about each customer and loan (for additional information, see the file `heloc_data_dictionary-2.xlsx`). The first 23 columns contain information known to the company prior to the approval of the application based on his/her credit history (i.e., observable information), while the last column (`RiskPerformance`) holds the outcome of granting the loan, specifically, whether or not the customer was late in his/her payments. \n",
                "\n",
                "Our goal in this assignment is to predict `RiskPerformance` based on the observable information. \n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "03gbufxkjn4q1qj1xsx41qd",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "### (q1)\n",
                "Initialize the variables `X` to hold the data/design matrix (the first 23 columns containing the features) and `Y` to hold the labels (the last column). Convert the values in `Y` to 1 and 0 for the labels \"Bad\" and \"Good\", respectively. This conversion allows us to compute the average value in the column `Y` to estimate the probability of defaulting. For example, averaging over the entire data frame would tell us the percentage of customers who defaulted, while averaging on a subset of customer would tell us the probability that a customer within this group defaults. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {
                "cellIdentifier": "hlcq7ormidu8r4bgqedui",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "X = df.iloc[:, :-1]\n",
                "Y = df.iloc[:, -1]\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n",
                "Y = Y.map({\"Bad\": 1, \"Good\": 0})\n",
                "default_probability = Y.mean()\n",
                "print(f\"Overall probability of defaulting: {default_probability:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {
                "cellIdentifier": "c1vpu0pbm9cwq1ja42ju3k",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q1b_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['X']\n",
                "diff = sol.compare(X, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing X'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {
                "cellIdentifier": "rjp5w68sasdvgzu4f2gyg",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q1c_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['Y']\n",
                "diff = sol.compare(Y, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing Y'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "8ejdgjwzkv972dw7ku5m2x",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "`X` should be a matrix (data frame) with 9871 rows and 23 columns, while `Y` is a vector (series) with 9871 values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {
                "cellIdentifier": "7qct4o9dc556shsmifrpfn",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['X'].head(2) # illustrate the output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {
                "cellIdentifier": "lhpn2wvaixdm3u5qdftpw",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['Y'].head(2) # illustrate the output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {
                "cellIdentifier": "g2q48wszfkenn8yy0arts",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "print(ANSWER_KEY['X'].shape, ANSWER_KEY['Y'].shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "vb5xk91g5u8oidtfamy6v",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "### (q2) \n",
                "\n",
                "Use the function `train_test_split` to split the data into train and test sets. Allocate 20% of your data to the test set (`test_size=0.2`), and set the parameter `random_state` to 1234. This number was arbitrarily chosen and its purpose is to guarantee that whenever the command  `train_test_split` is executed, the data will be partitioned the same way. This is important for replicability (so that you and others could replicate the analysis) and to prevent contamination of the test set.\n",
                "\n",
                "Specifically, initialize the following variables `X_train, X_test, Y_train, Y_test` according to their names (whether they hold the train or test set, of the data matrix `X` or the labels `Y`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {
                "cellIdentifier": "6lvwsrarens4ytobjj60uf",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1234)\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {
                "cellIdentifier": "7sp65gy8fsznp7eizv90m",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q2a_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['X_train']\n",
                "diff = sol.compare(X_train, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing X_train'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {
                "cellIdentifier": "06lcsoe7tyz6cx9sekhg1",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q2b_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['X_test']\n",
                "diff = sol.compare(X_test, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing X_test'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {
                "cellIdentifier": "i3747j3m94f6gnue0rgygy",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q2c_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['Y_train']\n",
                "diff = sol.compare(Y_train, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing Y_train'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {
                "cellIdentifier": "15qkjehdu936l7bqhiktdn",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q2d_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['Y_test']\n",
                "diff = sol.compare(Y_test, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing Y_test'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {
                "cellIdentifier": "8vsnoayk6wouwyqlz55i4",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "print('The shapes of X_train, X_test, Y_train, Y_test:')\n",
                "print(ANSWER_KEY['X_train'].shape, ANSWER_KEY['X_test'].shape, ANSWER_KEY['Y_train'].shape, ANSWER_KEY['Y_test'].shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "gafebdozzouovex2fzf8",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "# Part 2: Preprocessing\n",
                "\n",
                "Recall from previous assignments that our data contains missing values encoded by -7,-8, and -9. We next discuss and apply different techniques to handle missing values and transform our data matrix to become more amenable to learning. \n",
                "\n",
                "### (q3)\n",
                "To facilitate the visualization, combine  `X_train` and `Y_train` to a data frame called `df_train`. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {
                "cellIdentifier": "9dd1flm5ygaih6wf20us9l",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "df_train = pd.concat([X_train, Y_train], axis=1)\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {
                "cellIdentifier": "55nmyijzu0wdhwhg8pvm4g",
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "# example of output\n",
                "ANSWER_KEY['df_train'].head(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {
                "cellIdentifier": "grnvsuyuhw4l4jnnsl4qr",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q3_0",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['df_train']\n",
                "diff = sol.compare(df_train, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing df_train'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "p30g82iab68kz44plow76",
                "vocVersion": 1.1
            },
            "source": [
                "Let's plot the default risk as a function of the feature `ExternalRiskEstimate`. To this end, aggregate the values in the data frame `df_train` by computing the average risk (average value of `RiskPerformance`) per `ExternalRiskEstimate`. Store the results in the series `means` where the values are the risk estimates and indexes are the corresponding values of the `ExternalRiskEstimate`.\n",
                "\n",
                "Hint: use the function `.groupby()`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {
                "cellIdentifier": "ogwjqzym4ugcwnlh4ldutn",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "means = df_train.groupby('ExternalRiskEstimate')['RiskPerformance'].mean()\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {
                "cellIdentifier": "1of6bgp40gki0tmrkdn1j",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q3_1",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['means']\n",
                "diff = sol.compare(means, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing means'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {
                "cellIdentifier": "gn0azhlu6ecrj6h2sny4a",
                "scrolled": true,
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "# example of output\n",
                "print(ANSWER_KEY['means'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "87nmojnmjg9qm5k7r8xap",
                "vocVersion": 1.1
            },
            "source": [
                "For example, we see 0.875 of the customers whose `ExternalRiskEstimate` is equal to 51 were late on their payments.\n",
                "\n",
                "Similarly to `means`, create the variable `counts` which counts the number of customers with a certain `ExternalRiskEstimate`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {
                "cellIdentifier": "jug6c6ys1joc9g1r5xf3ki",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "counts = df_train.groupby(\"ExternalRiskEstimate\")[\"RiskPerformance\"].count()\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {
                "cellIdentifier": "1pwvv8xf7zcujbk0di3fy",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q3_2",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['counts']\n",
                "diff = sol.compare(counts, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing counts'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {
                "cellIdentifier": "oimp28qa7tahgjzpwc8gn",
                "scrolled": true,
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "# example of output\n",
                "print(ANSWER_KEY['counts'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "rfk0rpu5lppif6qbarwa",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "For example, there are 14 customers in the train data for whom `ExternalRiskEstimate=50`.\n",
                "\n",
                "Let's plot the default risk as a function of the `ExternalRiskEstimate` and the corresponding counts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {
                "cellIdentifier": "mwvuq1sdr28mihpgn79dfs",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "scrolled": true,
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1,2, figsize=(20,7))\n",
                "ANSWER_KEY['means'].plot.bar(ax=axes[0], title='Probability of defaulting vs. ExternalRiskEstimate')\n",
                "ANSWER_KEY['counts'].plot.bar(ax=axes[1], title='Number of observations vs. ExternalRiskEstimate')\n",
                "plt.tight_layout()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "lbht6ok13u8ncd8axcjzi",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "We observe that\n",
                "- The risk of defaulting is, generally, monotoincally decreaing in the `ExternalRiskEstimate` (left figure). This is to be expected from the documentation of the data (see `heloc_data_dictionary-2.xlsx`).\n",
                "- The number of observations whose `ExternalRiskEstimate` are smaller than 54 or larger than 91 is small (right figure). Therefore, the risk estimate is more noisy in those ranges. Focusing on the interval [54,91] reveals an even stronger trend.\n",
                "- There is a small number of missing values of `ExternalRiskEstimate` (8 to be exact, see below), and most of them defaulted. \n",
                "- Encoding missing values as a small value (-9) makes some sense in that according to the plot, smaller values of  `ExternalRiskEstimate` have higher risk. One is left to wonder why -9? This choice is rather arbitrary (why not -100 or -1000?)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {
                "cellIdentifier": "xer1vcody6gg7s3rwii7jf",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['counts'].loc[-9], ANSWER_KEY['means'].loc[-9] # count the number of observations in the training data where ExternalRiskEstimate is missing, and estimate the probability of defaulting using simple average"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "1jl7rsxeq0nqmr3e103go",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "__Preprocessing__\n",
                "\n",
                "In the feature preprocessing stage, we transform the values of the data matrix to facilitate learning. We could replace missing values, apply functions to transform features, and/or add additional features. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "1u39kr5piod0xu6upxev55",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "So what should we do about the missing values in the column `ExternalRiskEstimate`? \n",
                "* We could remove rows (observations) or columns (features)    \n",
                "    - if we remove rows we will lose data from 8 rows out of ~8000. Not too bad if we don't need to remove additional rows because of missing values in other features.\n",
                "    - removing the column `ExternalRiskEstimate` does not make sense here.\n",
                "* We could replace missing values\n",
                "    - with mean/median value of the feature? \n",
                "    - with minimal value of the feature? (in our 8 observations the risk was quite high)\n",
                "    - with a value corresponding to the respective percentile (0.875)?\n",
                "    - use more sophisticated methods? \n",
                "\n",
                "\n",
                "When deciding between the above options, we need to know why the value is missing from our data in the first place. Is it a random glitch in the system? should we expect similar behavior in the future? would we want our model to make predictions when there are missing values in this (or other) features? \n",
                "\n",
                "\n",
                "For simplicity, let's assume that whenever the `ExternalRiskEstimate` is missing, we don't want our model to make predictions. Based on this, we will remove from our data any rows where the the `ExternalRiskEstimate` is missing."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "dikfbabd32vh3xucmsyf",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Update the variable `X_train, X_test, Y_train, Y_test` by removing any observation where the feature `ExternalRiskEstimate` is missing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {
                "cellIdentifier": "g1jaymo8ylwoyk9vlk7cpj",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "mask_train = ~X_train[\"ExternalRiskEstimate\"].isin([-7, -8, -9])\n",
                "mask_test = ~X_test[\"ExternalRiskEstimate\"].isin([-7, -8, -9])\n",
                "\n",
                "X_train = X_train[mask_train]\n",
                "Y_train = Y_train[mask_train]\n",
                "\n",
                "X_test  = X_test[mask_test]\n",
                "Y_test  = Y_test[mask_test]\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {
                "cellIdentifier": "0fawbh3p2w3ukb9b4lxh3gd",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q3a_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['X_train_updated']\n",
                "diff = sol.compare(X_train, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing X_train'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {
                "cellIdentifier": "121vql112mffxadklcaszb",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q3b_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['X_test_updated']\n",
                "diff = sol.compare(X_test, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing X_test'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {
                "cellIdentifier": "kv3xp0v1iwzdb6uwyj8dl",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q3c_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['Y_train_updated']\n",
                "diff = sol.compare(Y_train, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing Y_train'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {
                "cellIdentifier": "x840w5uwdfafe9ef4jpyp",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q3d_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['Y_test_updated']\n",
                "diff = sol.compare(Y_test, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing Y_test'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {
                "cellIdentifier": "bf16et7meh9b0hqtxqkuqn",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "print('Before removing observations\\nThe shapes of X_train, X_test, Y_train, Y_test:')\n",
                "print(ANSWER_KEY['X_train'].shape, ANSWER_KEY['X_test'].shape, ANSWER_KEY['Y_train'].shape, ANSWER_KEY['Y_test'].shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "metadata": {
                "cellIdentifier": "2u6a5rmpulz02fd7u78ea7k",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "print('After removing observations\\nThe shapes of X_train, X_test, Y_train, Y_test:')\n",
                "print(ANSWER_KEY['X_train_updated'].shape, ANSWER_KEY['X_test_updated'].shape, ANSWER_KEY['Y_train_updated'].shape, ANSWER_KEY['Y_test_updated'].shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "6ad5j1rmgdvmrxo8e5bl5q",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "We see that a total of 10 rows were removed from our data (train and test).\n",
                "\n",
                "Let's look at the remaining missing values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {
                "cellIdentifier": "8sqjivktev30l8fq0cko3",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "# you implemented similar code in the previous assignment\n",
                "df_count_missing = pd.concat([(X_train==-7).sum(), (X_train==-8).sum(), (X_train==-9).sum()], axis=1)\n",
                "df_count_missing.columns = [-7,-8,-9]\n",
                "df_count_missing"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "p7vezdetxkq8wxrn6iq9vy",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "We see that there are no longer `-9` (missing) values in the data. \n",
                "\n",
                "We turn to handling the other missing values `-7` and `-8`. Let's assume for simplicity that these values are informative and that whatever generated them in the data that we have would generate them also in the future. This could be a reasonable assumption, for example, for the feature `MSinceMostRecentDelq` that indicates the number of months since last delinquency, where for customers who were never late on their payments the corresponding values is missing. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {
                "cellIdentifier": "unaikwbt8uc8og1ojzv2e6",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cell-c4a825a282dbd7fd",
                    "locked": true,
                    "points": 0,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN HIDDEN TEST\n",
                "if GENERATE_ANSWER_KEY and 0: \n",
                "    feature = 'MSinceMostRecentDelq'\n",
                "    means = df_train.groupby(feature)['RiskPerformance'].mean()\n",
                "    counts = df_train.groupby(feature)['RiskPerformance'].count()\n",
                "    fig, axes = plt.subplots(1,2, figsize=(20,7))\n",
                "    means.plot.bar(ax=axes[0], title='Probability of defaulting vs. ExternalRiskEstimate')\n",
                "    counts.plot.bar(ax=axes[1], title='Number of observations vs. ExternalRiskEstimate')\n",
                "    plt.tight_layout()\n",
                "    plt.savefig('Risk vs MSinceMostRecentDelq.png')\n",
                "### END HIDDEN TEST"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "sh87n3l8njej0ylwy9q1f",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Let's create a similar plot of risk vs. `MSinceMostRecentDelq`:\n",
                "<!--img src='Risk vs MSinceMostRecentDelq.png'-->"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "metadata": {
                "cellIdentifier": "0ki588q2sigkecl17y7kv",
                "scrolled": true,
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "# please run this cell\n",
                "Image(filename='Risk vs MSinceMostRecentDelq.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "3t91qgtyqmg7g1cqwimwul",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "We observe that\n",
                "- Risk is generally decreasing in `MSinceMostRecentDelq` (as the data documentation suggests `heloc_data_dictionary-2.xlsx`).\n",
                "- The risk at -7 and -8 seems to behave differently from the rest. It is not clear that setting the missing values to -7 and -8 is right (these values seem to break the trend).\n",
                "- The number of observations drops as `MSinceMostRecentDelq` increases.\n",
                "\n",
                "Let's focus on the non-negative values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "metadata": {
                "cellIdentifier": "5jy39w7oybe65f9i7bg13r",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN HIDDEN TEST\n",
                "if GENERATE_ANSWER_KEY and 0: \n",
                "    feature = 'MSinceMostRecentDelq'\n",
                "    means = df_train.groupby(feature)['RiskPerformance'].mean()\n",
                "    counts = df_train.groupby(feature)['RiskPerformance'].count()\n",
                "    fig, axes = plt.subplots(1,2, figsize=(20,7))\n",
                "    means[means.index>=0].plot.bar(ax=axes[0], title='Probability of defaulting vs. ExternalRiskEstimate')\n",
                "    counts[counts.index>=0].plot.bar(ax=axes[1], title='Number of observations vs. ExternalRiskEstimate')\n",
                "    plt.tight_layout()\n",
                "    plt.savefig('Risk vs MSinceMostRecentDelq - no missing.png')\n",
                "### END HIDDEN TEST"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "u640kjj8rsgmpix2lsbygm",
                "vocVersion": 1.1
            },
            "source": [
                "<!--img src='Risk vs MSinceMostRecentDelq - no missing.png'-->"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "metadata": {
                "cellIdentifier": "0ijilefh19o6v4z9kg8dj",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "# please run this cell\n",
                "Image(filename='Risk vs MSinceMostRecentDelq - no missing.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "n1bdn7flbig5br1ejatm",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "The trend seems stronger now (especially when `MSinceMostRecentDelq` is not too large where the number customers' count is relatively larger)\n",
                "\n",
                "So how should we transform the values of the feature `MSinceMostRecentDelq`? \n",
                "* We could add dummy variables to indicate the values -7 and -8. This way our predictive models could adjust to these special values. \n",
                "* In some cases, it could make sense to replace the missing values with average/median values of each column. \n",
                "* There are more sophisticated methods, some of which are implemented in scikit-learn (https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute). Additional methods can be found in the academic literature (e.g., you could search for \"impute missing values\" on Google Scholar: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C33&q=impute+missing+values&btnG=).\n",
                "* Another approach is to manually inspect the figure above. For example, we might conjecture that the functional relation between risk and `MSinceMostRecentDelq` is monotonically decreasing up to a certain point (perhaps 50?) and then it is constant. We might try to add a binary feature such as `MSinceMostRecentDelq>50` and/or `max(50-MSinceMostRecentDelq,0)`. As another example, if we're trying to fit a linear model, we might apply a transformation using the logarithmic or exponential function to make this function more linear or more evenly distributed.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "729485uz4wcpsi80mc2vi",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "In practice, one should think carefully when transforming each feature and understand the causes of missing values. Due to lack of access to the process that generated this data, and for our educational purposes, we will apply the following transformation:\n",
                "1. For every column with missing values (-7 or -8), we add a feature with the same name, concatenated by the term \"=-7\" or \"=-8\". For example, for the feature `MSinceMostRecentDelq`, we will add the binary features `MSinceMostRecentDelq=-7` and `MSinceMostRecentDelq=-8`, which are equal to 1 when the value under   `MSinceMostRecentDelq` is equal to `-7` and `-8`, respectively.\n",
                "2. We will replace the missing values of each feature by the average value of the respective feature.  \n",
                "\n",
                "\n",
                "To this end, we will use scikit-learn preprocessing functions. Let's start with a small example:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {
                "cellIdentifier": "f71b00zr9vqukuojr24t59",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "X1 = np.array([[ -7,  1,  2],\n",
                "               [  4,  0, -7],\n",
                "               [ -8,  1, -7],\n",
                "               [ 10, 20, 30]])\n",
                "df1 = pd.DataFrame(X1, columns=['A','B','C'])\n",
                "df1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "1eoets3ihrziv26gvhrd1",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "We created the dataframe `df1` that has three columns \"A\",\"B\",\"C\", which contains some missing values indicated by `-7` and `-8`. \n",
                "\n",
                "We next use the scikit-learn object `MissingIndicator` to transform the dataframe into a dataframe that only contain indicators for missing values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {
                "cellIdentifier": "b53313u6fkajmgm3uhcy2",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "from sklearn.impute import MissingIndicator\n",
                "minus_7_indicator_transformer = MissingIndicator(missing_values=-7, features='missing-only').fit(df1)\n",
                "minus_7_indicator_transformer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "wcz0atb1ks22vjq5ic8lp",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "The above code created a transformer (an objects that transforms data matrixes and features) called `minus_7_indicators`. Using the parameters `missing_values=-7`, we specified that  -7 is the value being used to denote missing values. The other parameter `features='missing-only`  specifies that we will only keep columns with missing values. In our case, Columns A and C contain missing values but not column B. If we apply the transformation we would get two columns, one indicating missing values in column A and the second indicating missing values in column C:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {
                "cellIdentifier": "d9x4by90jbvtp3suescf49",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "arr1_t = minus_7_indicator_transformer.transform(df1)\n",
                "arr1_t"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "ttvednk6zqb7o8jmf425w",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "The variable `arr1_t` (which stands for array 1 transformed) contains the transformed values. Notice that the value `-8` has not been transformed since we only specified -7 as missing value (by setting `missing_values=-7`).\n",
                "Running `minus_7_indicators.features_` will tell us which of the columns were transformed:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {
                "cellIdentifier": "mu8kjf3w3e7st2zqf1ev",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "minus_7_indicator_transformer.features_"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "51f94uyrxk7wdikuvbctzq",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "These are the first and last columns of `df1`, which correspond to A and C:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {
                "cellIdentifier": "uzz79ycu6ulh1fi1why4n",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "df1.columns.values[minus_7_indicator_transformer.features_]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "wtcdc7j304wdi2kdgm5x",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "An advantage of defining this transformer is that it can be applied to new data points: "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {
                "cellIdentifier": "e2sy3dp4bqilzyqglqt7es",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "slideshow": {
                    "slide_type": ""
                },
                "tags": [],
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "minus_7_indicator_transformer.transform([[1,1,-7]]) # A is not missing here, and C is missing (this is the output of transforming this new observation)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "nv5ip9yi93gy0p3bdaex",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Similarly, let's create additional features for the missing value -8: "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {
                "cellIdentifier": "wk3z5dtt4shuaojxr4c8f",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "minus_8_indicator_transformer = MissingIndicator(missing_values=-8, features='missing-only').fit(df1) # notice the -8\n",
                "arr2_t = minus_8_indicator_transformer.transform(df1)\n",
                "arr2_t"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {
                "cellIdentifier": "kkxpz40frgcxu7hmpxem5m",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "minus_8_indicator_transformer.features_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {
                "cellIdentifier": "ey956rka8we7c7h4wqnq2t",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "df1.columns.values[minus_8_indicator_transformer.features_]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "pugmgqkpxlsga8wx7ik33r",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "The dataframe `df1` only contains 1 value of -8 in the column A, which is why the transformer `minus_8_indicator_transformer` returns a single column.\n",
                "\n",
                "There are a few more steps that we are left to do: \n",
                "1. combine df1, arr1_t, and arr2_t into a single dataframe or array\n",
                "2. set the appropriate feature names (for convenience)\n",
                "3. replace missing values with average values in each column\n",
                "\n",
                "To combine the original data frame (`df1`) and the new features (`arr1_t` and `arr2_t`), we will use scikit-learn's `FeatureUnion` object. Before we do that, we define another transformer (which takes a dataframe and returns one transformed according to some logic), which in our case does nothing. We will call it `do_nothing_imputer`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {
                "cellIdentifier": "8rjz1u3xff3gx0hursy45",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "# a \"do nothing\" imputer (will be useful later in this exercise)\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.impute import SimpleImputer\n",
                "do_nothing_imputer = ColumnTransformer([(\"Imputer -7 to mean\", SimpleImputer(missing_values=-7, strategy='mean'), [])], remainder='passthrough')\n",
                "do_nothing_imputer.fit_transform(df1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {
                "cellIdentifier": "tl6fpunvmkxanqkikgayf",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "print(df1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "2iooe7a0rbnmqwga87ez1m",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "We see that we get the exact same output, with the exception of the data being returned as a numpy array."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {
                "cellIdentifier": "qupzansypxivnc4ll74rrf",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "from sklearn.pipeline import FeatureUnion\n",
                "union = FeatureUnion([(\"do nothing\", do_nothing_imputer),\n",
                "                      (\"missing_minus_7\", MissingIndicator(missing_values=-7, features='missing-only')),\n",
                "                      (\"missing_minus_8\", MissingIndicator(missing_values=-8, features='missing-only'))])\n",
                "arr1_extended = union.fit_transform(df1)\n",
                "arr1_extended"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "3flw4y3y7hnalo4fqgheek",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "FeatureUnion takes a dataframe (or array) and creates multiple copies of it (3 above, one corresponding to each element of the list given to it as a parameter). Each copy is sent through a transformer that transforms the datamatrix (such as `minus_8_indicator_transformer` we defined earlier). Finally, the transformed copies are combined (the union operation in math combines sets of elements, and in this case, sets of features). \n",
                "\n",
                "The first transformer which we call \"do nothing\" only passes the copied data it received. This is because we would like to extend the features space, but also keep the original features. The second and third transformers add binary features for columns with missing values of -7 and -8, respectively (this is equivalent to what we've done earlier).\n",
                "\n",
                "The result is stored in `arr1_extended`. The first 3 columns are the original features, the next two columns indicate missing values of -7 in columns A and C, and the last column indicates missing values in column A. The information about the column names, however, is not shown above as the returned value is an array. We will therefore add columns manually."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "oiern3y0kre9bgkhdehrq",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "We can obtain the original features names from the dataframe `df1`:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "metadata": {
                "cellIdentifier": "vrwj355y77g5qfrv5n9wjm",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "print(df1.columns.values.tolist()) # these are the original features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "113bs38ovjbekcu7ymfnw8h",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "We can obtain the next two features from the transformer `minus_7_indicator_transformer`, mapping the column indexes to feature names:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "metadata": {
                "cellIdentifier": "ohzmoa3s448n9s73zh7co",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "col_names_minus_7 = df1.columns.values[minus_7_indicator_transformer.features_].tolist() \n",
                "col_names_minus_7  # these two columns indicate missing value of -7"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "1ni0oxu4wcs4311y8j6nam",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "We add the text \"-7\" to indicate that these binary columns represent missing values of -7. We use Python's built-in function `map` to apply a function to each element of a list. In this case, the function simply concatenates the string '=-7' to each element in list of column names."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "metadata": {
                "cellIdentifier": "m52flspyqgla5pjxanliyf",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "col_names_minus_7 = list(map(lambda s:str(s)+'=-7',col_names_minus_7)) # we run over the pervious value\n",
                "col_names_minus_7"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "p859xyp2aabekr2d7zy29",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "We do the same for the last column, which corresponds to missing values of -8:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "metadata": {
                "cellIdentifier": "sg66a8n64tge1quz70i27",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "col_names_minus_8 = df1.columns.values[minus_8_indicator_transformer.features_].tolist() \n",
                "col_names_minus_8 = list(map(lambda s:str(s)+'=-8',col_names_minus_8))\n",
                "col_names_minus_8"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "himm5q132cnsdne4j7dngh",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Putting it all together, we get the following list of column names:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {
                "cellIdentifier": "6r9nanfxvokkxoxkuis1he",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "columns_all = df1.columns.values.tolist() + col_names_minus_7 + col_names_minus_8\n",
                "columns_all"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "y864yt82dbhhmsfpm0zivv",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Using the combined array `arr1_extended` and the complete list of column names `columns_all`, we create the dataframe `df1_t` (where t stands for transformed)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "metadata": {
                "cellIdentifier": "5nc7yg5hufjulwqeh548q",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "df1_t = pd.DataFrame(arr1_extended, columns=columns_all)\n",
                "df1_t"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "8qebiy5iyclbqd84lhs12k",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Finally, we replace missing values of -7 and -8 with the average values in each column. While a bit convoluted, we do it in two steps, first transforming values of -7 to -8, and then replacing all values of -8 with the mean values. (This is due to a limitation of scikit-learn where `SimpleImputer` only accepts one value as indicating missing values)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "metadata": {
                "cellIdentifier": "h3lhg9d3meso68symsjjyh",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "arr1_t2 = SimpleImputer(missing_values=-7, strategy='constant', fill_value=-8).fit_transform(df1_t)\n",
                "arr1_t2 "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {
                "cellIdentifier": "ml6ocgfbhzf1wfffgc0dua",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "arr1_t3 = SimpleImputer(missing_values=-8, strategy='mean').fit_transform(arr1_t2)\n",
                "arr1_t3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "cbpye89wprrv3ndt82n3",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "We see that `arr1_t2` is similar to `df1_t` with values of -7 replaced by -8. In `arr1_t3` we further replace -8 with the average value in each column (check for yourself).\n",
                "\n",
                "We write the entire transformation code in the following code cell."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "metadata": {
                "cellIdentifier": "nixnfj1yzvbjwvzqlnk1",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "from sklearn.pipeline import Pipeline\n",
                "\n",
                "do_nothing_imputer = ColumnTransformer([(\"Imputer -7 to mean\", SimpleImputer(missing_values=-7, strategy='mean'), [])], remainder='passthrough')\n",
                "\n",
                "feature_expansion = FeatureUnion([(\"do nothing\", do_nothing_imputer),\n",
                "                                  (\"add features for -7\", MissingIndicator(missing_values=-7, features='missing-only')),\n",
                "                                  (\"add features for -8\", MissingIndicator(missing_values=-8, features='missing-only'))])\n",
                " \n",
                "pipe_example = Pipeline([(\"expand features\", feature_expansion), \n",
                "                 (\"replace -7 with -8\", SimpleImputer(missing_values=-7, strategy='constant', fill_value=-8)),\n",
                "                 (\"replace -8 with mean\", SimpleImputer(missing_values=-8, strategy='mean'))])\n",
                "\n",
                "arr1_transformed = pipe_example.fit_transform(df1)\n",
                "arr1_transformed"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "f0oqnuqcx0as87m0gnj3x",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Explanation:\n",
                "* do_nothing_imputer: the transformer that returns the exact input\n",
                "* feature_expansion: the transformer that copies its input 3 times and sends each copy to the transformers \"do nothing\", \"add features for -7\", and \"add features for -8\"\n",
                "* pipe: the transformer that first applies \"feature_expansion\" (defined earlier), then applies \"replace -7 with -8\", and finally applies \"replace -8 with mean\". \n",
                "* when we run pipe_example.fit_transform(df1) we perform the transformations in pipe_example on the values in df1\n",
                "* we store the transformed values in `arr1_transformed`\n",
                "\n",
                "\n",
                "Below is the code that produces the column names of the transformed data matrix:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "metadata": {
                "cellIdentifier": "wktfe82ywnce3zglf1wt0a",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "col_names_minus_7 = df1.columns.values[minus_7_indicator_transformer.features_].tolist() \n",
                "col_names_minus_7 = list(map(lambda s:str(s)+'=-7',col_names_minus_7)) \n",
                "col_names_minus_8 = df1.columns.values[minus_8_indicator_transformer.features_].tolist() \n",
                "col_names_minus_8 = list(map(lambda s:str(s)+'=-8',col_names_minus_8))\n",
                "columns_all = df1.columns.values.tolist() + col_names_minus_7 + col_names_minus_8\n",
                "columns_all"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "ey8x5kg1w5d1o0sgorelu",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "And finally, we combine the transformed matrix with the column names."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {
                "cellIdentifier": "d2khizee30ln3q4hhacrm",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "df1_t = pd.DataFrame(arr1_transformed, columns=columns_all)\n",
                "df1_t"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "66ucav8zlq7yxlvkgr9r8k",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "### (q4)\n",
                "\n",
                "Similarly to the example above, assign to the variable `pipeline` a pipeline that extends `X_train` with binary variables that indicate missing values of -7 and -8 in each of the columns, and replaces the missing values with the average value in each column. Then apply it to transform our training data `X_train` into the array `arr_X_train_t`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {
                "cellIdentifier": "nxd3lh0ph60tma70fraus",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "inus_7_indicator_transformer = MissingIndicator(missing_values=-7, features='missing-only').fit(X_train)\n",
                "minus_8_indicator_transformer = MissingIndicator(missing_values=-8, features='missing-only').fit(X_train)\n",
                "\n",
                "do_nothing_imputer = ColumnTransformer([(\"Imputer -7 to mean\", SimpleImputer(missing_values=-7, strategy='mean'), [])], remainder='passthrough')\n",
                "feature_expansion = FeatureUnion([(\"do nothing\", do_nothing_imputer),\n",
                "                                  (\"add features for -7\", MissingIndicator(missing_values=-7, features='missing-only')),\n",
                "                                  (\"add features for -8\", MissingIndicator(missing_values=-8, features='missing-only'))])\n",
                "\n",
                "pipeline = Pipeline([(\"expand features\", feature_expansion), \n",
                "                     (\"replace -7 with -8\", SimpleImputer(missing_values=-7, strategy='constant', fill_value=-8)),\n",
                "                     (\"replace -8 with mean\", SimpleImputer(missing_values=-8, strategy='mean'))])\n",
                "\n",
                "\n",
                "arr_X_train_t = pipeline.fit_transform(X_train)\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "metadata": {
                "cellIdentifier": "0updm53rdwho0ujxnyut4yvj",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q4a",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(arr_X_train_t.shape == ANSWER_KEY['arr_X_train_t'].shape), 'test if the dimensions of arr_X_train_t are correct'\n",
                "assert(np.isclose(ANSWER_KEY['arr_X_train_t'], arr_X_train_t, rtol=0, atol=0.01).all()), 'testing arr_X_train_t'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "metadata": {
                "cellIdentifier": "7q04t49nh5nswlooc4tv3r",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "print('The dimensions of X_train:',X_train.shape)\n",
                "print('The dimensions of the transformed X_train:',ANSWER_KEY['arr_X_train_t'].shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "dhnctcfpeise1gett5nu5u",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Observe that our transformation did not change the number of rows (observations), only the number of features."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "b7fn79ttfuhaq9pany6biu",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Set the variable `column_names` to hold the list of column names of the transformed dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "metadata": {
                "cellIdentifier": "360xahlw564ftc2nalw59s",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "col_names_minus_7 = X_train.columns.values[minus_7_indicator_transformer.features_].tolist()\n",
                "col_names_minus_7 = list(map(lambda s: str(s) + '=-7', col_names_minus_7))\n",
                "\n",
                "col_names_minus_8 = X_train.columns.values[minus_8_indicator_transformer.features_].tolist()\n",
                "col_names_minus_8 = list(map(lambda s: str(s) + '=-8', col_names_minus_8))\n",
                "\n",
                "column_names = X_train.columns.values.tolist() + col_names_minus_7 + col_names_minus_8\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "metadata": {
                "cellIdentifier": "08ihxbnwyt34uze0j574bls",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "scrolled": true,
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "# expected output\n",
                "ANSWER_KEY['column_names']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "metadata": {
                "cellIdentifier": "swdprmg9jalwwztqk5eebd",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q4b",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(ANSWER_KEY['column_names'] == column_names), 'test column_names'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "bukqmn12rrwpdm29f9te4",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Set the variable `X_train_t` to the dataframe holding the transformed data (similar to arr_X_train_t only with the appropriate column names)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 111,
            "metadata": {
                "cellIdentifier": "micurslifdbm4x9a6gccr",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "X_train_t = df1_t = pd.DataFrame(arr_X_train_t, columns=column_names)\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "metadata": {
                "cellIdentifier": "7lsvz81phabiy870ard9z",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q4c",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['X_train_t']\n",
                "diff = sol.compare(X_train_t)\n",
                "assert(len(diff)==0), 'testing X_train_t'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "g73r3coy4qpnijqosatde",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Let's look at the transformed dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "metadata": {
                "cellIdentifier": "am4chbr2plskja2bonz8p9",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['X_train_t'].describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "vbj25bmjttndtnau02q3m",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "We observe that \n",
                "* There are now 34 features (in comparison to the original 23)\n",
                "* Missing values were transformed (the minimal value in each column is no longer -7 or -8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "6lfx55qvsdets6hi9v7ysi",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "We can conveniently see the list of features using the function `.info()`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "metadata": {
                "cellIdentifier": "n4ag92rylhrsf2izyphcif",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "X_train_t.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "151927ypxy73qn9dvbiig3",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Let's stop for a second and think. Why did we create this pipeline? Why not simply use pandas function, Python for loop, etc.? \n",
                "\n",
                "The reason is that we are going to train a model on the transformed dataset. That is, the model will expect 34 features (rather than the original 23 features). What if we need to make prediction about a new observation? This new observation is likely to be formatted in the original features space (from which there are 23 features). We must therefore transform it before making prediction. If we do it in pandas and Python, we need to duplicate the entire transformation code to do just that. \n",
                "\n",
                "This is how we do it in scikit-learn once we define pipelines. Suppose that our new data consists of observations 3 and 7 in the test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {
                "cellIdentifier": "ipg6pvl9omtx24trt9318",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "new_data =  X_test.iloc[[3,7],:]\n",
                "new_data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {
                "cellIdentifier": "djkyr28z4yqexexq8b8nc5",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "new_data_t = pipeline.transform(new_data) # Notice that we run transform() and not fit_transform()!\n",
                "new_data_t = pd.DataFrame(new_data_t, columns=column_names)\n",
                "new_data_t"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "ibtg6iqdzrk22ecfxb6do",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "That's all. The dataframe `new_data_t`  contains the transformed (expanded and imputed) data. This was done using 2 lines of code!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "t7gki2fw6faklzwkaqag5r",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Transform the test set `X_test` using the pipeline and create the data frame `X_test_t` which contains the transformed data and the column names. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {
                "cellIdentifier": "biqrga2qtbqem6w9zxa2rw",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "X_test_t = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {
                "cellIdentifier": "ezjy5jfqj7ejatexqosoe8",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q4d",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['X_test_t']\n",
                "diff = sol.compare(X_test_t)\n",
                "assert(len(diff)==0), 'testing X_test_t'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {
                "cellIdentifier": "aofl9nle2g7b0fn27oyqn",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "# expected output\n",
                "ANSWER_KEY['X_test_t'].head(2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "ot4lo0c00jcgs4nnwxy3pl",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "If you got the answer right, you noticed the difference in applying transformers to the train and test sets\n",
                "- train: pipeline.fit_transform(X_train)\n",
                "- test: pipeline.transform(X_test)\n",
                "\n",
                "When we run `.fit()` or `.fit_transform()` the transformer learns from the data given to it. For example, in the command\n",
                "\n",
                "    SimpleImputer(missing_values=-8, strategy='mean').fit_transform(arr1_t2)\n",
                "    \n",
                "we learned the mean values in each column of `arr1_t2` so we could use it to impute missing values. The function `fit` learns how to impute missing values using the given data, the function `transform` performs the transformation, and the function `fit_transform` does both. To avoid data leakage between the test and train sets, it is important that we only learn from training data and not from the test data prior to evaluating our models using the test data."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "89jlizmtoknnm14p4wkatm",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "# Part 3: Model training and evaluation\n",
                "\n",
                "Now that we have a pipeline that preprocessed the data, we can start training models. We will train 3 models: classification tree, logistic regression, and K-nearest neighbors. \n",
                "\n",
                "We will use two methods for evaluation: validation set (simple cross validation) and cross-validation\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "pfjiwnjs7vdhn7xvr2lyl",
                "vocVersion": 1.1
            },
            "source": [
                "## Validation set\n",
                "\n",
                "Let' further split the train data to train and validation sets."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "gr3i33xwg20gbtwhgu80d7",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "### (q5) \n",
                "\n",
                "Use the function `train_test_split` to split `X_train_t` into train and validation sets called. Allocate 25% of the train data  to the validation set (`test_size=0.25`), and set the parameter `random_state` to 1234. Initialize the following variables `X_train_t_tr, X_train_t_val, Y_train_t_tr, Y_train_t_val` according to their names (whether they hold the train or validation set, of the data matrix `X` or the labels `Y`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {
                "cellIdentifier": "2ykfnct786xb7mx281gpc",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "X_train_t_tr  = \"replace this string with your answer\"\n",
                "X_train_t_val = \"replace this string with your answer\"\n",
                "Y_train_t_tr  = \"replace this string with your answer\"\n",
                "Y_train_t_val = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {
                "cellIdentifier": "kayajbfqskv17tzrz2lt",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q5a_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['X_train_t_tr']\n",
                "diff = sol.compare(X_train_t_tr, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing X_train_t_tr'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {
                "cellIdentifier": "zlb5grosb8phvyf2u5vtb",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q5b_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['X_train_t_val']\n",
                "diff = sol.compare(X_train_t_val, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing X_train_t_val'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {
                "cellIdentifier": "6rkrqjl5mchv7fg0ml7asl",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q5c_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['Y_train_t_tr']\n",
                "diff = sol.compare(Y_train_t_tr, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing Y_train_t_tr'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {
                "cellIdentifier": "1shqq62ge666mzmndjvrqm",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q5d_",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['Y_train_t_val']\n",
                "diff = sol.compare(Y_train_t_val, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing Y_train_t_val'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {
                "cellIdentifier": "j6mk1jfamuuy3zf8vyb9",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "print('The shape of X:', X.shape)\n",
                "print('The shape of X_test_t:', X_test_t.shape)\n",
                "print('The shape of X_train_t:', X_train_t.shape)\n",
                "print('The shapes of X_train_t_tr, X_train_t_val, Y_train_t_tr, Y_train_t_val:', ANSWER_KEY['X_train_t_tr'].shape, ANSWER_KEY['X_train_t_val'].shape, ANSWER_KEY['Y_train_t_tr'].shape, ANSWER_KEY['Y_train_t_val'].shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {
                "cellIdentifier": "07j32n754i3gaew3phtb35g",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "print('The proportion of train:validation:test data is %.1f:%.1f:%.1f'%(len(Y_train_t_tr)/len(Y), len(Y_train_t_val)/len(Y), len(Y_test)/len(Y)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "8kn18ocga2m4am5fmz9e",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "When we use the validation set approach, we use 60% of the data to train models (`X_train_t_tr`,`Y_train_t_tr`), we use 20% of the data for model selection (`X_train_t_val`,`Y_train_t_val`), and the remaining 20% for final evaluation (`X_test_t_tr`,`Y_test`)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "ysdgp58qrclve6rywrc53",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Let's train models!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "metadata": {
                "cellIdentifier": "zidpm11nhwlqbywe5sqpvh",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "from sklearn import tree, linear_model, neighbors            \n",
                "clf_tree    = tree.DecisionTreeClassifier().fit(X_train_t_tr, Y_train_t_tr)\n",
                "clf_log_reg = linear_model.LogisticRegression(max_iter=10000).fit(X_train_t_tr, Y_train_t_tr) \n",
                "clf_knn     = neighbors.KNeighborsClassifier().fit(X_train_t_tr, Y_train_t_tr)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "djre7do72iiom5iltfna8",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "The parameter `max_iter` was set to 10000 in the logistic regression model to ensure that the algorithm converges, that is,  the estimation process reached steady parameter values as part of its execution. \n",
                "\n",
                "Next, we evaluate the performance of the models on the validation set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "metadata": {
                "cellIdentifier": "zhtdgjzs16nys2jpri54fd",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "from sklearn.metrics import accuracy_score\n",
                "print('Decision tree accuracy: %.3f'%accuracy_score(Y_train_t_val, clf_tree.predict(X_train_t_val)))\n",
                "print('Logistic regression accuracy: %.3f'%accuracy_score(Y_train_t_val, clf_log_reg.predict(X_train_t_val)))\n",
                "print('KNN accuracy: %.3f'%accuracy_score(Y_train_t_val, clf_knn.predict(X_train_t_val)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "f4v8bnnyqf7tcol8r7xupe",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Observe that models can be controlled by various hyper-parameters that could have big impact over their behavior: \n",
                "\n",
                "    DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, ccp_alpha=0.0)    \n",
                "    \n",
                "    LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
                "    \n",
                "    KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)\n",
                "    \n",
                "\n",
                "Understanding how each model works is important to tune the hyper-parameters. Additionally, scikit-learn offers some functions to automate this process. We'll get back to this later."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "5koeuxqjclwcwk8zz0ghlr",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "### (q6)\n",
                "\n",
                "Let's use cross-validation to evaluate models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "metadata": {
                "cellIdentifier": "hxakn9xirm2stumm2q4rx",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "clf_tree    = tree.DecisionTreeClassifier().fit(X_train_t_tr, Y_train_t_tr)\n",
                "clf_log_reg = linear_model.LogisticRegression(max_iter=10000).fit(X_train_t_tr, Y_train_t_tr) \n",
                "clf_knn     = neighbors.KNeighborsClassifier().fit(X_train_t_tr, Y_train_t_tr)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "metadata": {
                "cellIdentifier": "7pzwfdk7rbmyyvtpwrakha",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "from sklearn.model_selection import cross_validate\n",
                "cv_results_tree = cross_validate(tree.DecisionTreeClassifier(), X_train_t, Y_train, cv=5, return_estimator=True)\n",
                "cv_results_log_reg = cross_validate(linear_model.LogisticRegression(max_iter=10000), X_train_t, Y_train, cv=5, return_estimator=True)\n",
                "cv_results_knn = cross_validate(neighbors.KNeighborsClassifier(), X_train_t, Y_train, cv=5, return_estimator=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "m8jp8u47876sqnetiah8s",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Notice that we run the cross validation on the entire training data `X_train_t` (which includes the previously separated validation set). The cross-validation assures that we evaluate model performance on data that was not used in its training. Note that the running time is 5 times longer.\n",
                "\n",
                "Let's inspect the returned object."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {
                "cellIdentifier": "qgjvdx1ork1iuvoxbrn61",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "cv_results_tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "metadata": {
                "cellIdentifier": "xorolwxn1lj8gwbnbfxccr",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "cv_results_tree['test_score'] # these are 5 evaluations (since we specified cv=5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "metadata": {
                "cellIdentifier": "jwps48sd3aeahijtk54l4c",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "print('Classification tree - CV accuracy score %.3f'%cv_results_tree['test_score'].mean()) # this is their average value\n",
                "print('Logistic regresion - CV accuracy score %.3f'%cv_results_log_reg['test_score'].mean()) # this is their average value\n",
                "print('KNN - CV accuracy score %.3f'%cv_results_knn['test_score'].mean()) # this is their average value"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "zoz6j7omhcfu39txewpdnd",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Reminder: these are the validation set scores"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {
                "cellIdentifier": "weewqpgjfj9iouyvrel7w7",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "print('Classification tree - validation accuracy score: %.3f'%accuracy_score(Y_train_t_val, clf_tree.predict(X_train_t_val)))\n",
                "print('Logistic regresion - validation accuracy score: %.3f'%accuracy_score(Y_train_t_val, clf_log_reg.predict(X_train_t_val)))\n",
                "print('KNN - validation accuracy score: %.3f'%accuracy_score(Y_train_t_val, clf_knn.predict(X_train_t_val)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "bgwe6qox9zob84bfn1mcxb",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "CV tends to be more accurate but slower compared to validation set. If we have a large dataset, validation set would typically be sufficient.\n",
                "\n",
                "Typically, we would explore more models at this point, and try to narrow down the list to a few promising models. Next we would perform hyper-parameter tuning to try improve their performance. Here, we will focus only on the logistic regression model. We will use `GridSearchCV` to perform hyperparameter tuning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "metadata": {
                "cellIdentifier": "qlp4me718fnyacp6kcao",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "scrolled": true,
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "from sklearn.model_selection import GridSearchCV\n",
                "param_grid = [{'max_depth':[1,2,3,4,5],  \n",
                "               'criterion':[\"gini\", \"entropy\"],            \n",
                "               'min_samples_split':[2,5,10],              \n",
                "               'min_samples_leaf':[10,20,30]}]\n",
                "clf_tree = tree.DecisionTreeClassifier()\n",
                "grid_search = GridSearchCV(clf_tree, param_grid, cv=3, scoring='accuracy')\n",
                "grid_search.fit(X_train_t,Y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "metadata": {
                "cellIdentifier": "gx0w45y06lww475hochqs9",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "scrolled": true,
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "cvres = grid_search.cv_results_ # the variable that stores the grid search results\n",
                "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):  # iterate over the tested configurations\n",
                "    print(mean_score, params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "6ji0z74pmo6tlxuqfrsa4",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "With some effort we improved the accuracy of decision trees from 64% to 71%. \n",
                "\n",
                "These are the best hyper-parameters we found so far"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {
                "cellIdentifier": "zdimjiyuy9gfiww8hq1ctp",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "grid_search.best_params_"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "caj87srtxbaavciqgk2wil",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "And this is the classifier that was trained on the entire train data after completing the cross validation and choosing the best configuration:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {
                "cellIdentifier": "xqje48jffs3ucp6gjf7gk",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "grid_search.best_estimator_ # variable holding the best classifier (fitted on the entire dataset)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "l8hpcv17j2nghfnu34er3j",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "In the validation set approach, we would typically do something similar. Once we selected the best model and hyper parameters, we would train a model on the entire train data (train+validation)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "d4fubtv5hk4x5ngqwvfydr",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Note that while we used accuracy for model selection (recall using `scoring='accuracy'` in `GridSearchCV`), this need not be our only or even our main criterion. Let's compute a few other metrics that are commonly used in practice. \n",
                "\n",
                "Let's train a model on the train set which we can evaluate on the validation set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {
                "cellIdentifier": "y15u3vsa7h606tg7ps9w4",
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "clf_tree = tree.DecisionTreeClassifier(max_depth=4,min_samples_leaf=20).fit(X_train_t_tr, Y_train_t_tr)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "sy2nug5jaumnxen03rp3co",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Note that while we used accuracy for model selection (recall using `scoring='accuracy'` in `GridSearchCV`), this need not be our only or even main criterion. Let's compute a few other metrics that are commonly used in practice. \n",
                "\n",
                "In the following questions initialize the variables to their respective values. You may use the lecture notes on \"The mechanics of ML\", Wikipedia (https://en.wikipedia.org/wiki/Precision_and_recall), and scikit-learn documentation (https://scikit-learn.org/stable/modules/model_evaluation.html).\n",
                "\n",
                "* conf_matrix: the confusion matrix where columns represent predictions (0,1) and rows the true labels (0,1). Note that this is opposite to the convention in the Wikipedia webpage above (but is consistent with scikit-learn).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {
                "cellIdentifier": "1mit11343oko2rarui0o5b",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "conf_matrix = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "metadata": {
                "cellIdentifier": "g550fk0xggh0ft0ob232lpb",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "# expected output\n",
                "print(ANSWER_KEY['conf_matrix'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "metadata": {
                "cellIdentifier": "xlzhztplesat9qyxx0zzrk",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q6a",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['conf_matrix'], conf_matrix, rtol=0, atol=0.01).all()), 'testing conf_matrix'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "metadata": {
                "cellIdentifier": "11x73eqvq76ggu23uei4zgl",
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "accuracy = \"replace this string with your answer\"\n",
                "tn = \"replace this string with your answer\"\n",
                "fp = \"replace this string with your answer\"\n",
                "fn = \"replace this string with your answer\"\n",
                "tp = \"replace this string with your answer\"\n",
                "tpr = \"replace this string with your answer\"\n",
                "fpr = \"replace this string with your answer\"\n",
                "tnr = \"replace this string with your answer\"\n",
                "fnr = \"replace this string with your answer\"\n",
                "recall = \"replace this string with your answer\"\n",
                "precision = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 103,
            "metadata": {
                "cellIdentifier": "yo7h8ubbux0y4z08h6e0uo",
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "print(\"Accuracy: %.2f, Recall: %.2f, Precision: %.2f\"%(ANSWER_KEY['accuracy'], ANSWER_KEY['recall'], ANSWER_KEY['precision']),'\\n')\n",
                "print(\"Put differently, our predictions are correct %.0f%% of the time, the model catches %.0f%% of the defaulting customers, and the model is correct %.0f%% of times it predicts 'Bad'.\"%(ANSWER_KEY['accuracy']*100, ANSWER_KEY['recall']*100, ANSWER_KEY['precision']*100))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 104,
            "metadata": {
                "cellIdentifier": "my9lubzu50d6ygq873lyoj",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q6b1",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['accuracy'], accuracy, rtol=0, atol=0.01).all()), 'testing accuracy'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 105,
            "metadata": {
                "cellIdentifier": "poi77detjuoprkwb4cofi",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q6b2",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['tn'], tn, rtol=0, atol=0.01).all()), 'testing tn'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 106,
            "metadata": {
                "cellIdentifier": "gtcaxr525pcom2jojw0938",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q6b3",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['fp'], fp, rtol=0, atol=0.01).all()), 'testing fp'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 107,
            "metadata": {
                "cellIdentifier": "g473tnqau9i236tve4a2w5",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q6b4",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['fn'], fn, rtol=0, atol=0.01).all()), 'testing fn'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "metadata": {
                "cellIdentifier": "4u6xhufnvi5eo18hvp8pfd",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q6b5",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['tp'], tp, rtol=0, atol=0.01).all()), 'testing tp'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "metadata": {
                "cellIdentifier": "t6w9tv8nm4cshq9813cwhq",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q6b6",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['fpr'], fpr, rtol=0, atol=0.01).all()), 'testing fpr'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "metadata": {
                "cellIdentifier": "qze0niwrc4m8wgoncgxgs",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q6b7",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['tpr'], tpr, rtol=0, atol=0.01).all()), 'testing tpr'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 111,
            "metadata": {
                "cellIdentifier": "dosodv6zijh6ynjqzvaoy2",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q6b8",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['tnr'], tnr, rtol=0, atol=0.01).all()), 'testing tnr'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "metadata": {
                "cellIdentifier": "oqxeakkptnfc0j3lmolq95",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q6b9",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['fnr'], fnr, rtol=0, atol=0.01).all()), 'testing fnr'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "metadata": {
                "cellIdentifier": "ojnbio761m683h4xbzpcp",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q6b10",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['recall'], recall, rtol=0, atol=0.01).all()), 'testing recall'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 114,
            "metadata": {
                "cellIdentifier": "og2ag88906ncku6w9xuljo",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "part2-q6b11",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['precision'], precision, rtol=0, atol=0.01).all()), 'testing precision'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "m5i27o303voqvnpgqe0d",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "Finally, let's draw the ROC curve for our model `clf_tree`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 115,
            "metadata": {
                "cellIdentifier": "jndoxy8mg3j8uea8anjvfn",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "from sklearn import metrics\n",
                "scores = clf_tree.predict_proba(X_train_t_val)[:,1]\n",
                "fpr, tpr, thresholds = metrics.roc_curve(Y_train_t_val, scores)\n",
                "auc = metrics.auc(fpr, tpr)\n",
                "plt.figure(figsize=(5,5))\n",
                "lw = 2\n",
                "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % auc)\n",
                "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
                "plt.xlim([0.0, 1.0])\n",
                "plt.ylim([0.0, 1.05])\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate (Recall)')\n",
                "plt.title('Receiver operating characteristic example')\n",
                "plt.legend(loc=\"lower right\");\n",
                "plt.plot([ANSWER_KEY['fpr']], [ANSWER_KEY['recall']], marker=\"x\", markeredgewidth=5, markersize=12);"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "ynoyn36fvkcu101cp0yprn",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "The ROC curve simultaneously shows a series of models that differ by a certain threshold value (often on the probability for predicting 1 vs. 0). The 'x' marks the trained model `clf_tree`. Note that by slightly modifying the threshold we could move along the ROC curve to find a better tradeoff between Recall and FPR. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "3h0ksadw92o1mssva38p",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": [
                "# Summary\n",
                "\n",
                "\n",
                "In this homework assignment, we practiced the mechanics of training and evaluating predictive models. By now, you should be familiar with the following concepts: \n",
                "* Preprocessing, imputers, and pipelines\n",
                "* Model training, Hyper-parameter tuning, grid search, and prediction\n",
                "* Validation set and cross validation\n",
                "* Confusion matrix\n",
                "* Performance metrics\n",
                "\n",
                "While this exercise illustrated the main steps of training and evaluating predictive models, in practice you will face other issues such as: \n",
                "* How to formulate the prediction problem? What exactly should you predict? \n",
                "* How to extract data from your company database and transform it into standard form?\n",
                "* Which preprocessing method to use? (you could have many alternatives)\n",
                "* Which models to use? (and which shouldn't you use?) \n",
                "* How to evaluate the model? Which of the various metrics we discussed is most appropriate? \n",
                "* Is the result good enough? Is 80% accuracy satisfactory? Is 90%? or 95%? \n",
                "\n",
                "In most cases there is no universal answer to these questions which greatly depend on the business context. It is important to understand who will be using your model,  what is their background, and what is the implication of making different types of errors in prediction. \n",
                "\n",
                "Nevertheless, the techniques (and code examples) that we covered here will be useful for any project."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 116,
            "metadata": {
                "cellIdentifier": "fu8h2xpubgfkqpe5rn41o",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cell-56a7f83815146078",
                    "locked": true,
                    "points": 0,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "if GENERATE_ANSWER_KEY: \n",
                "    with open(ANSWER_KEY_FILE_NAME, \"wb\") as f:\n",
                "        pickle.dump( ANSWER_KEY,  f)\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "29b5nwxvdu4687m00vauxo",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "vocVersion": 1.1
            },
            "source": []
        }
    ],
    "metadata": {
        "celltoolbar": "Create Assignment",
        "kernelspec": {
            "display_name": "Python 3 [3.10]",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.2"
        },
        "latex_envs": {
            "LaTeX_envs_menu_present": true,
            "autoclose": false,
            "autocomplete": true,
            "bibliofile": "biblio.bib",
            "cite_by": "apalike",
            "current_citInitial": 1,
            "eqLabelWithNumbers": true,
            "eqNumInitial": 1,
            "hotkeys": {
                "equation": "Ctrl-E",
                "itemize": "Ctrl-I"
            },
            "labels_anchors": false,
            "latex_user_defs": false,
            "report_style_numbering": false,
            "user_envs_cfg": false
        },
        "toc": {
            "base_numbering": 1,
            "nav_menu": [],
            "number_sections": false,
            "sideBar": true,
            "skip_h1_title": false,
            "title_cell": "Table of Contents",
            "title_sidebar": "Contents",
            "toc_cell": false,
            "toc_position": {
                "height": "calc(100% - 180px)",
                "left": "10px",
                "top": "150px",
                "width": "272.969px"
            },
            "toc_section_display": true,
            "toc_window_display": true
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}